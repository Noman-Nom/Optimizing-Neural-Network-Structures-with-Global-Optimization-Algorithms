{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PSO implementation for hyperparameter tuning"
      ],
      "metadata": {
        "id": "8OrzLjnat7GW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9TMOCVUJS0N",
        "outputId": "d18ee649-5a16-4aaa-a4c5-a2ca7b09a926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oboVRXp1Jj7T",
        "outputId": "9bf8e2c3-187f-4dcf-e20b-049d9ceed13b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib numpy --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqhGRNTRJsgW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgbksVj3K8mk"
      },
      "outputs": [],
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE_p5YMaK-jy"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.00934\n",
        "hidden_size = 97\n",
        "batch_size = 241\n",
        "num_epochs = 15000\n",
        "input_size = 28 * 28\n",
        "num_classes = 10\n",
        "save_dir = \"/content/drive/MyDrive/PSO_Training_Results\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwMoB7iqLCHV",
        "outputId": "2fb91e3a-5c56-43af-a9eb-56bb997fc4b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 32.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.01MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 7.85MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.60MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "denbdpVfLEVq"
      },
      "outputs": [],
      "source": [
        "model = SimpleNN(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xqDRhT-LGQU"
      },
      "outputs": [],
      "source": [
        "start_epoch = 0\n",
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "\n",
        "ckpt_path = os.path.join(save_dir, \"model_latest.pth\")\n",
        "if os.path.exists(ckpt_path):\n",
        "    checkpoint = torch.load(ckpt_path)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    start_epoch = checkpoint[\"epoch\"]\n",
        "    train_loss_history = checkpoint[\"loss_history\"]\n",
        "    train_accuracy_history = checkpoint[\"acc_history\"]\n",
        "    print(f\"Resumed from epoch {start_epoch}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVHcT1LXLb1Z",
        "outputId": "65070ac5-ebc4-495e-82bd-d9a987db46c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/15000] - Loss: 0.4570, Accuracy: 86.31%\n",
            "Epoch [100/15000] - Loss: 0.0731, Accuracy: 97.86%\n",
            "Epoch [200/15000] - Loss: 0.0642, Accuracy: 98.26%\n",
            "Epoch [300/15000] - Loss: 0.0532, Accuracy: 98.72%\n",
            "Epoch [400/15000] - Loss: 0.0836, Accuracy: 98.53%\n",
            "Epoch [500/15000] - Loss: 0.0419, Accuracy: 99.16%\n",
            "Epoch [600/15000] - Loss: 0.0460, Accuracy: 99.27%\n",
            "Epoch [700/15000] - Loss: 0.0802, Accuracy: 98.95%\n",
            "Epoch [800/15000] - Loss: 0.0607, Accuracy: 99.26%\n",
            "Epoch [900/15000] - Loss: 0.0397, Accuracy: 99.50%\n",
            "Epoch [1000/15000] - Loss: 0.0298, Accuracy: 99.59%\n",
            "Epoch [1100/15000] - Loss: 0.0576, Accuracy: 99.48%\n",
            "Epoch [1200/15000] - Loss: 0.0736, Accuracy: 99.41%\n",
            "Epoch [1300/15000] - Loss: 0.0648, Accuracy: 99.53%\n",
            "Epoch [1400/15000] - Loss: 0.0455, Accuracy: 99.61%\n",
            "Epoch [1500/15000] - Loss: 0.0766, Accuracy: 99.48%\n",
            "Epoch [1600/15000] - Loss: 0.0581, Accuracy: 99.60%\n",
            "Epoch [1700/15000] - Loss: 0.0672, Accuracy: 99.57%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.reshape(-1, input_size)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    train_accuracy_history.append(epoch_accuracy)\n",
        "\n",
        "    if (epoch + 1) % 100 == 0 or epoch == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "    # 🔁 Save model checkpoint every 500 epochs\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        torch.save({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss_history\": train_loss_history,\n",
        "            \"acc_history\": train_accuracy_history\n",
        "        }, ckpt_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}